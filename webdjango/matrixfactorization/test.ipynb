{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.optimize\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('u.user', sep='|', names=u_cols)\n",
    "n_users = users.shape[0]\n",
    "print('Number of users:', n_users)\n",
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Myrecommend():\n",
    "    def normalizeRatings(myY, myR):\n",
    "        # Tính trung bình các đánh giá\n",
    "        Ymean = np.sum(myY, axis=1) / np.sum(myR, axis=1)\n",
    "        Ymean = Ymean.reshape((Ymean.shape[0], -1))\n",
    "        return myY - Ymean, Ymean\n",
    "\n",
    "    def flattenParams(myX, myTheta):\n",
    "        return np.concatenate((myX.flatten(), myTheta.flatten()))\n",
    "\n",
    "    def reshapeParams(flattened_XandTheta, mynm, mynu, mynf):\n",
    "        assert flattened_XandTheta.shape[0] == int(mynm * mynf + mynu * mynf)\n",
    "        reX = flattened_XandTheta[: int(mynm * mynf)].reshape((mynm, mynf))\n",
    "        reTheta = flattened_XandTheta[int(mynm * mynf) :].reshape((mynu, mynf))\n",
    "        return reX, reTheta\n",
    "\n",
    "    def cofiCostFunc(myparams, myY, myR, mynu, mynm, mynf, mylambda=0.0):\n",
    "        myX, myTheta = reshapeParams(myparams, mynm, mynu, mynf)\n",
    "        term1 = myX.dot(myTheta.T)\n",
    "        term1 = np.multiply(term1, myR)\n",
    "        cost = 0.5 * np.sum(np.square(term1 - myY))\n",
    "        # Thêm phần regularization\n",
    "        cost += (mylambda / 2.0) * np.sum(np.square(myTheta))\n",
    "        cost += (mylambda / 2.0) * np.sum(np.square(myX))\n",
    "        return cost\n",
    "\n",
    "    def cofiGrad(myparams, myY, myR, mynu, mynm, mynf, mylambda=0.0):\n",
    "        myX, myTheta = reshapeParams(myparams, mynm, mynu, mynf)\n",
    "        term1 = myX.dot(myTheta.T)\n",
    "        term1 = np.multiply(term1, myR)\n",
    "        term1 -= myY\n",
    "        Xgrad = term1.dot(myTheta)\n",
    "        Thetagrad = term1.T.dot(myX)\n",
    "        # Thêm phần regularization\n",
    "        Xgrad += mylambda * myX\n",
    "        Thetagrad += mylambda * myTheta\n",
    "        return flattenParams(Xgrad, Thetagrad)\n",
    "\n",
    "    \n",
    "    mynu = df_train.user_name.nunique()\n",
    "    mynm = df_train.product_id.nunique()\n",
    "    mynf = 10\n",
    "    Y = np.zeros((mynm, mynu))\n",
    "\n",
    "    user_to_column = {user_name: idx for idx, user_name in enumerate(df['user_name'].unique())}\n",
    "    product_to_row = {product: idx for idx, product in enumerate(df['product_id'].unique())}\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        Y[product_to_row[row.product_id], user_to_column[row.user_name]] = row.rating\n",
    "\n",
    "    R = (Y != 0).astype(int)\n",
    "\n",
    "    Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "    X = np.random.rand(mynm, mynf)\n",
    "    Theta = np.random.rand(mynu, mynf)\n",
    "    myflat = flattenParams(X, Theta)\n",
    "\n",
    "    result = scipy.optimize.minimize(\n",
    "        fun=cofiCostFunc,\n",
    "        x0=myflat,\n",
    "        args=(Ynorm, R, mynu, mynm, mynf, 3),\n",
    "        method=\"TNC\",\n",
    "        jac=cofiGrad,\n",
    "        options={\"maxiter\": 300},\n",
    "    )\n",
    "\n",
    "    resX, resTheta = reshapeParams(result.x, mynm, mynu, mynf)\n",
    "    prediction_matrix = resX.dot(resTheta.T)\n",
    "    return prediction_matrix, Ymean, product_to_row, user_to_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uuCF(object):\n",
    "    def __init__(self, Y_data, k, sim_func=cosine_similarity):\n",
    "        self.Y_data = np.array(Y_data)\n",
    "        self.k = k\n",
    "        self.sim_func = sim_func\n",
    "        self.Ybar = None\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
    "\n",
    "    def fit(self):\n",
    "        users = self.Y_data[:, 0]\n",
    "        self.Ybar = self.Y_data.copy()\n",
    "        self.mu = np.zeros((self.n_users,))\n",
    "        for n in range(self.n_users):\n",
    "            ids = np.where(users == n)[0].astype(np.int32)\n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            self.mu[n] = np.mean(ratings) if ids.size > 0 else 0\n",
    "            self.Ybar[ids, 2] = ratings - self.mu[n]\n",
    "        self.Ybar = sparse.coo_matrix(\n",
    "            (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])), (self.n_items, self.n_users)\n",
    "        ).tocsr()\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def pred(self, u, i):\n",
    "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\n",
    "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
    "        sim = self.S[u, users_rated_i]\n",
    "        nns = np.argsort(sim)[-self.k :]\n",
    "        nearest_s = sim[nns]\n",
    "        r = self.Ybar[i, users_rated_i[nns]]\n",
    "        eps = 1e-8\n",
    "        return (r * nearest_s).sum() / (np.abs(nearest_s).sum() + eps) + self.mu[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo data frame với thông tin người dùng, sản phẩm và đánh giá\n",
    "# Y_data = df[['user_name', 'product_id', 'rating']].values\n",
    "\n",
    "# # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "# train_data, test_data = train_test_split(Y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Tạo DataFrame cho tập huấn luyện\n",
    "# df_train = pd.DataFrame(train_data, columns=['user_name', 'product_id', 'rating'])\n",
    "\n",
    "# # Khởi tạo và chạy thử nghiệm cho Myrecommend với tham số tối ưu\n",
    "# prediction_matrix, Ymean, product_to_row, user_to_column = Myrecommend()\n",
    "\n",
    "# Tạo Y_pred cho Myrecommend trên tập kiểm tra\n",
    "# Y_pred_test = np.zeros_like(test_data[:, 2])\n",
    "# for idx, (user, product_id, rating) in enumerate(test_data):\n",
    "#     if product_id in product_to_row and user in user_to_column:\n",
    "#         Y_pred_test[idx] = prediction_matrix[product_to_row[product_id], user_to_column[user]] + Ymean[product_to_row[product_id]]\n",
    "#     else:\n",
    "#         Y_pred_test[idx] = np.mean(df_train['rating'])  # Giá trị trung bình nếu sản phẩm hoặc người dùng mới\n",
    "\n",
    "# # Khởi tạo uuCF và chạy thử nghiệm với k tối ưu\n",
    "# model = uuCF(train_data, k=10)\n",
    "# model.fit()\n",
    "\n",
    "# # Tạo Y_pred cho uuCF trên tập kiểm tra\n",
    "# Y_pred_uuCF_test = np.zeros_like(test_data[:, 2])\n",
    "# for idx, (user, product_id, rating) in enumerate(test_data):\n",
    "#     Y_pred_uuCF_test[idx] = model.pred(user, product_id)\n",
    "\n",
    "# # Tính sai số cho cả hai phương pháp trên tập kiểm tra\n",
    "# mae_myrecommend_test = mean_absolute_error(test_data[:, 2], Y_pred_test)\n",
    "# rmse_myrecommend_test = mean_squared_error(test_data[:, 2], Y_pred_test, squared=False)\n",
    "\n",
    "# mae_uucf_test = mean_absolute_error(test_data[:, 2], Y_pred_uuCF_test)\n",
    "# rmse_uucf_test = mean_squared_error(test_data[:, 2], Y_pred_uuCF_test, squared=False)\n",
    "\n",
    "# print(f\"MAE của Myrecommend trên tập kiểm tra: {mae_myrecommend_test}\")\n",
    "# print(f\"MSE của Myrecommend trên tập kiểm tra: {rmse_myrecommend_test}\")\n",
    "\n",
    "# print(f\"MAE của uuCF trên tập kiểm tra: {mae_uucf_test}\")\n",
    "# print(f\"MSE của uuCF trên tập kiểm tra: {rmse_uucf_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('u.user', sep='|', names=u_cols)\n",
    "n_users = users.shape[0]\n",
    "print('Number of users:', n_users)\n",
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate_train[:, :2] -= 1 # since indices start from 0\n",
    "#rate_test[:, :2] -= 1\n",
    "rs = uuCF(rate_train, k = 40)\n",
    "rs.fit()\n",
    "SE = 0 # squared error\n",
    "rate_train = rate_train[:, [1, 0, 2]]\n",
    "rate_test = rate_test[:, [1, 0, 2]]\n",
    "rs = uuCF(rate_train, k = 40)\n",
    "rs.fit()\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2])**2\n",
    "testRMSECF = SE/n_tests\n",
    "SE=0\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += abs(pred - rate_test[n, 2])\n",
    "testRMAECF = SE/n_tests\n",
    "SE=0\n",
    "n_trains=rate_train.shape[0]\n",
    "for n in range(n_trains):\n",
    "    pred = rs.pred(rate_train[n, 0], rate_train[n, 1])\n",
    "    SE += abs(pred - rate_train[n, 2])\n",
    "trainRMAECF = SE/n_trains\n",
    "SE=0\n",
    "for n in range(n_trains):\n",
    "    pred = rs.pred(rate_train[n, 0], rate_train[n, 1])\n",
    "    SE += (pred - rate_train[n, 2])**2\n",
    "trainRMSECF = SE/n_trains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(object):\n",
    "    def __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None,learning_rate = 0.5, max_iter = 1000, print_every = 100):\n",
    "        self.Y = Y # represents the utility matrix\n",
    "        self.K = K\n",
    "        self.lam = lam # regularization parameter\n",
    "        self.learning_rate = learning_rate # for gradient descent\n",
    "        self.max_iter = max_iter # maximum number of iterations\n",
    "        self.print_every = print_every # print loss after each a few iters\n",
    "        self.n_users = int(np.max(Y[:, 0])) + 1\n",
    "        self.n_items = int(np.max(Y[:, 1])) + 1\n",
    "        self.n_ratings = Y.shape[0] # number of known ratings\n",
    "        self.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit\n",
    "        self.W = np.random.randn(K, self.n_users) if Winit is None else Winit\n",
    "        self.b = np.random.randn(self.n_items) # item biases\n",
    "        self.d = np.random.randn(self.n_users) # user biases]\n",
    "\n",
    "    def loss(self):\n",
    "        L = 0\n",
    "        for i in range(self.n_ratings):\n",
    "        # user_id, item_id, rating\n",
    "            n, m, rating = int(self.Y[i,0]), int(self.Y[i,1]), self.Y[i,2]\n",
    "            L += 0.5*(self.X[m].dot(self.W[:, n])\\\n",
    "            + self.b[m] + self.d[n] - rating)**2\n",
    "        L /= self.n_ratings\n",
    "        # regularization, don’t ever forget this\n",
    "        return L + 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\n",
    "    def updateXb(self):\n",
    "        for m in range(self.n_items):\n",
    "            # get all users who rated item m and corresponding ratings\n",
    "            ids = np.where(self.Y[:, 1] == m)[0] # row indices of items m\n",
    "            user_ids, ratings=self.Y[ids, 0].astype(np.int32),self.Y[ids, 2]\n",
    "            Wm, dm = self.W[:, user_ids], self.d[user_ids]\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                xm = self.X[m]\n",
    "                error = xm.dot(Wm) + self.b[m] + dm - ratings\n",
    "                grad_xm = error.dot(Wm.T)/self.n_ratings + self.lam*xm\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.X[m] -= self.learning_rate*grad_xm.reshape(-1)\n",
    "                self.b[m] -= self.learning_rate*grad_bm\n",
    "    def updateWd(self): # and d\n",
    "        for n in range(self.n_users):\n",
    "            # get all items rated by user n, and the corresponding ratings\n",
    "            ids = np.where(self.Y[:,0] == n)[0] #indexes of items rated by n\n",
    "            item_ids,ratings=self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\n",
    "            Xn, bn = self.X[item_ids], self.b[item_ids]\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "                grad_dn = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= self.learning_rate*grad_wn.reshape(-1)\n",
    "                self.d[n] -= self.learning_rate*grad_dn    \n",
    "\n",
    "    def fit(self):\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateWd()\n",
    "            self.updateXb()\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                rmse_train = self.evaluate_RMSE(self.Y)\n",
    "                #print('iter = %d, loss = %.4f, RMSE train = %.4f'%(it + 1,self.loss(), rmse_train))\n",
    "\n",
    "    def pred(self, u, i):\n",
    "        \"\"\"\n",
    "        predict the rating of user u for item i\n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]\n",
    "        return max(0, min(5, pred)) # 5-scale in MoviesLen\n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0] # number of test\n",
    "        SE = 0 # squared error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2])**2\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE\n",
    "\n",
    "    def evaluate_RMAE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0] # number of test\n",
    "        AE = 0 # absolute error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            AE += abs(pred - rate_test[n, 2])\n",
    "        MAE = AE / n_tests\n",
    "        return MAE\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "rs = MF(rate_train, K = 50, lam = .01, print_every = 5, learning_rate = 50,\n",
    "max_iter = 30)\n",
    "rs.fit()\n",
    "# evaluate on test data\n",
    "testRMSEMF = rs.evaluate_RMSE(rate_test)\n",
    "testRMAEMF=rs.evaluate_RMAE(rate_test)\n",
    "trainRMSEMF = rs.evaluate_RMSE(rate_train)\n",
    "trainRMAEMF=rs.evaluate_RMAE(rate_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model  Train RMSE  Test RMSE  Train MAE  Test MAE\n",
      "0    MF    0.911096   0.962395   0.718637  0.756910\n",
      "1    CF    0.530874   0.938663   0.600066  0.771578\n"
     ]
    }
   ],
   "source": [
    "comparison_table = pd.DataFrame({\n",
    "    'Model': ['MF', 'CF'],\n",
    "    'Train RMSE': [trainRMSEMF, trainRMSECF],\n",
    "    'Test RMSE': [testRMSEMF, testRMSECF],\n",
    "    'Train MAE': [trainRMAEMF, trainRMAECF],\n",
    "    'Test MAE': [testRMAEMF, testRMAECF]\n",
    "})\n",
    "\n",
    "print(comparison_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
