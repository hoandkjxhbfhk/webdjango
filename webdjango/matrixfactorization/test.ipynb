{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.optimize\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('u.user', sep='|', names=u_cols)\n",
    "n_users = users.shape[0]\n",
    "print('Number of users:', n_users)\n",
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Myrecommend():\n",
    "    def normalizeRatings(myY, myR):\n",
    "        # Tính trung bình các đánh giá\n",
    "        Ymean = np.sum(myY, axis=1) / np.sum(myR, axis=1)\n",
    "        Ymean = Ymean.reshape((Ymean.shape[0], -1))\n",
    "        return myY - Ymean, Ymean\n",
    "\n",
    "    def flattenParams(myX, myTheta):\n",
    "        return np.concatenate((myX.flatten(), myTheta.flatten()))\n",
    "\n",
    "    def reshapeParams(flattened_XandTheta, mynm, mynu, mynf):\n",
    "        assert flattened_XandTheta.shape[0] == int(mynm * mynf + mynu * mynf)\n",
    "        reX = flattened_XandTheta[: int(mynm * mynf)].reshape((mynm, mynf))\n",
    "        reTheta = flattened_XandTheta[int(mynm * mynf) :].reshape((mynu, mynf))\n",
    "        return reX, reTheta\n",
    "\n",
    "    def cofiCostFunc(myparams, myY, myR, mynu, mynm, mynf, mylambda=0.0):\n",
    "        myX, myTheta = reshapeParams(myparams, mynm, mynu, mynf)\n",
    "        term1 = myX.dot(myTheta.T)\n",
    "        term1 = np.multiply(term1, myR)\n",
    "        cost = 0.5 * np.sum(np.square(term1 - myY))\n",
    "        # Thêm phần regularization\n",
    "        cost += (mylambda / 2.0) * np.sum(np.square(myTheta))\n",
    "        cost += (mylambda / 2.0) * np.sum(np.square(myX))\n",
    "        return cost\n",
    "\n",
    "    def cofiGrad(myparams, myY, myR, mynu, mynm, mynf, mylambda=0.0):\n",
    "        myX, myTheta = reshapeParams(myparams, mynm, mynu, mynf)\n",
    "        term1 = myX.dot(myTheta.T)\n",
    "        term1 = np.multiply(term1, myR)\n",
    "        term1 -= myY\n",
    "        Xgrad = term1.dot(myTheta)\n",
    "        Thetagrad = term1.T.dot(myX)\n",
    "        # Thêm phần regularization\n",
    "        Xgrad += mylambda * myX\n",
    "        Thetagrad += mylambda * myTheta\n",
    "        return flattenParams(Xgrad, Thetagrad)\n",
    "\n",
    "    \n",
    "    mynu = df_train.user_name.nunique()\n",
    "    mynm = df_train.product_id.nunique()\n",
    "    mynf = 10\n",
    "    Y = np.zeros((mynm, mynu))\n",
    "\n",
    "    user_to_column = {user_name: idx for idx, user_name in enumerate(df['user_name'].unique())}\n",
    "    product_to_row = {product: idx for idx, product in enumerate(df['product_id'].unique())}\n",
    "\n",
    "    for row in df.itertuples():\n",
    "        Y[product_to_row[row.product_id], user_to_column[row.user_name]] = row.rating\n",
    "\n",
    "    R = (Y != 0).astype(int)\n",
    "\n",
    "    Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "    X = np.random.rand(mynm, mynf)\n",
    "    Theta = np.random.rand(mynu, mynf)\n",
    "    myflat = flattenParams(X, Theta)\n",
    "\n",
    "    result = scipy.optimize.minimize(\n",
    "        fun=cofiCostFunc,\n",
    "        x0=myflat,\n",
    "        args=(Ynorm, R, mynu, mynm, mynf, 3),\n",
    "        method=\"TNC\",\n",
    "        jac=cofiGrad,\n",
    "        options={\"maxiter\": 300},\n",
    "    )\n",
    "\n",
    "    resX, resTheta = reshapeParams(result.x, mynm, mynu, mynf)\n",
    "    prediction_matrix = resX.dot(resTheta.T)\n",
    "    return prediction_matrix, Ymean, product_to_row, user_to_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uuCF(object):\n",
    "    def __init__(self, Y_data, k, sim_func=cosine_similarity):\n",
    "        self.Y_data = np.array(Y_data)\n",
    "        self.k = k\n",
    "        self.sim_func = sim_func\n",
    "        self.Ybar = None\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1\n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
    "\n",
    "    def fit(self):\n",
    "        users = self.Y_data[:, 0]\n",
    "        self.Ybar = self.Y_data.copy()\n",
    "        self.mu = np.zeros((self.n_users,))\n",
    "        for n in range(self.n_users):\n",
    "            ids = np.where(users == n)[0].astype(np.int32)\n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            self.mu[n] = np.mean(ratings) if ids.size > 0 else 0\n",
    "            self.Ybar[ids, 2] = ratings - self.mu[n]\n",
    "        self.Ybar = sparse.coo_matrix(\n",
    "            (self.Ybar[:, 2], (self.Ybar[:, 1], self.Ybar[:, 0])), (self.n_items, self.n_users)\n",
    "        ).tocsr()\n",
    "        self.S = self.sim_func(self.Ybar.T, self.Ybar.T)\n",
    "\n",
    "    def pred(self, u, i):\n",
    "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\n",
    "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
    "        sim = self.S[u, users_rated_i]\n",
    "        nns = np.argsort(sim)[-self.k :]\n",
    "        nearest_s = sim[nns]\n",
    "        r = self.Ybar[i, users_rated_i[nns]]\n",
    "        eps = 1e-8\n",
    "        return (r * nearest_s).sum() / (np.abs(nearest_s).sum() + eps) + self.mu[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tạo data frame với thông tin người dùng, sản phẩm và đánh giá\n",
    "# Y_data = df[['user_name', 'product_id', 'rating']].values\n",
    "\n",
    "# # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "# train_data, test_data = train_test_split(Y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Tạo DataFrame cho tập huấn luyện\n",
    "# df_train = pd.DataFrame(train_data, columns=['user_name', 'product_id', 'rating'])\n",
    "\n",
    "# # Khởi tạo và chạy thử nghiệm cho Myrecommend với tham số tối ưu\n",
    "# prediction_matrix, Ymean, product_to_row, user_to_column = Myrecommend()\n",
    "\n",
    "# Tạo Y_pred cho Myrecommend trên tập kiểm tra\n",
    "# Y_pred_test = np.zeros_like(test_data[:, 2])\n",
    "# for idx, (user, product_id, rating) in enumerate(test_data):\n",
    "#     if product_id in product_to_row and user in user_to_column:\n",
    "#         Y_pred_test[idx] = prediction_matrix[product_to_row[product_id], user_to_column[user]] + Ymean[product_to_row[product_id]]\n",
    "#     else:\n",
    "#         Y_pred_test[idx] = np.mean(df_train['rating'])  # Giá trị trung bình nếu sản phẩm hoặc người dùng mới\n",
    "\n",
    "# # Khởi tạo uuCF và chạy thử nghiệm với k tối ưu\n",
    "# model = uuCF(train_data, k=10)\n",
    "# model.fit()\n",
    "\n",
    "# # Tạo Y_pred cho uuCF trên tập kiểm tra\n",
    "# Y_pred_uuCF_test = np.zeros_like(test_data[:, 2])\n",
    "# for idx, (user, product_id, rating) in enumerate(test_data):\n",
    "#     Y_pred_uuCF_test[idx] = model.pred(user, product_id)\n",
    "\n",
    "# # Tính sai số cho cả hai phương pháp trên tập kiểm tra\n",
    "# mae_myrecommend_test = mean_absolute_error(test_data[:, 2], Y_pred_test)\n",
    "# rmse_myrecommend_test = mean_squared_error(test_data[:, 2], Y_pred_test, squared=False)\n",
    "\n",
    "# mae_uucf_test = mean_absolute_error(test_data[:, 2], Y_pred_uuCF_test)\n",
    "# rmse_uucf_test = mean_squared_error(test_data[:, 2], Y_pred_uuCF_test, squared=False)\n",
    "\n",
    "# print(f\"MAE của Myrecommend trên tập kiểm tra: {mae_myrecommend_test}\")\n",
    "# print(f\"MSE của Myrecommend trên tập kiểm tra: {rmse_myrecommend_test}\")\n",
    "\n",
    "# print(f\"MAE của uuCF trên tập kiểm tra: {mae_uucf_test}\")\n",
    "# print(f\"MSE của uuCF trên tập kiểm tra: {rmse_uucf_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n"
     ]
    }
   ],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('u.user', sep='|', names=u_cols)\n",
    "n_users = users.shape[0]\n",
    "print('Number of users:', n_users)\n",
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_train[:, :2] -= 1 # since indices start from 0\n",
    "rate_test[:, :2] -= 1\n",
    "rs = uuCF(rate_train, k = 40)\n",
    "rs.fit()\n",
    "SE = 0 # squared error\n",
    "# rate_train = rate_train[:, [1, 0, 2]]\n",
    "# rate_test = rate_test[:, [1, 0, 2]]\n",
    "rs = uuCF(rate_train, k = 40)\n",
    "rs.fit()\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += (pred - rate_test[n, 2])**2\n",
    "testRMSECF = sqrt(SE/n_tests)\n",
    "SE=0\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "    SE += abs(pred - rate_test[n, 2])\n",
    "testRMAECF = SE/n_tests\n",
    "SE=0\n",
    "n_trains=rate_train.shape[0]\n",
    "for n in range(n_trains):\n",
    "    pred = rs.pred(rate_train[n, 0], rate_train[n, 1])\n",
    "    SE += abs(pred - rate_train[n, 2])\n",
    "trainRMAECF = SE/n_trains\n",
    "SE=0\n",
    "for n in range(n_trains):\n",
    "    pred = rs.pred(rate_train[n, 0], rate_train[n, 1])\n",
    "    SE += (pred - rate_train[n, 2])**2\n",
    "trainRMSECF = sqrt(SE/n_trains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(object):\n",
    "    def __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None,learning_rate = 0.5, max_iter = 1000, print_every = 100):\n",
    "        self.Y = Y # represents the utility matrix\n",
    "        self.K = K\n",
    "        self.lam = lam # regularization parameter\n",
    "        self.learning_rate = learning_rate # for gradient descent\n",
    "        self.max_iter = max_iter # maximum number of iterations\n",
    "        self.print_every = print_every # print loss after each a few iters\n",
    "        self.n_users = int(np.max(Y[:, 0])) + 1\n",
    "        self.n_items = int(np.max(Y[:, 1])) + 1\n",
    "        self.n_ratings = Y.shape[0] # number of known ratings\n",
    "        self.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit\n",
    "        self.W = np.random.randn(K, self.n_users) if Winit is None else Winit\n",
    "        self.b = np.random.randn(self.n_items) # item biases\n",
    "        self.d = np.random.randn(self.n_users) # user biases]\n",
    "\n",
    "    def loss(self):\n",
    "        L = 0\n",
    "        for i in range(self.n_ratings):\n",
    "        # user_id, item_id, rating\n",
    "            n, m, rating = int(self.Y[i,0]), int(self.Y[i,1]), self.Y[i,2]\n",
    "            L += 0.5*(self.X[m].dot(self.W[:, n])\\\n",
    "            + self.b[m] + self.d[n] - rating)**2\n",
    "        L /= self.n_ratings\n",
    "        # regularization, don’t ever forget this\n",
    "        return L + 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\n",
    "    def updateXb(self):\n",
    "        for m in range(self.n_items):\n",
    "            # get all users who rated item m and corresponding ratings\n",
    "            ids = np.where(self.Y[:, 1] == m)[0] # row indices of items m\n",
    "            user_ids, ratings=self.Y[ids, 0].astype(np.int32),self.Y[ids, 2]\n",
    "            Wm, dm = self.W[:, user_ids], self.d[user_ids]\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                xm = self.X[m]\n",
    "                error = xm.dot(Wm) + self.b[m] + dm - ratings\n",
    "                grad_xm = error.dot(Wm.T)/self.n_ratings + self.lam*xm\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.X[m] -= self.learning_rate*grad_xm.reshape(-1)\n",
    "                self.b[m] -= self.learning_rate*grad_bm\n",
    "    def updateWd(self): # and d\n",
    "        for n in range(self.n_users):\n",
    "            # get all items rated by user n, and the corresponding ratings\n",
    "            ids = np.where(self.Y[:,0] == n)[0] #indexes of items rated by n\n",
    "            item_ids,ratings=self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\n",
    "            Xn, bn = self.X[item_ids], self.b[item_ids]\n",
    "            for i in range(30): # 30 iteration for each sub problem\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "                grad_dn = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= self.learning_rate*grad_wn.reshape(-1)\n",
    "                self.d[n] -= self.learning_rate*grad_dn    \n",
    "\n",
    "    def fit(self):\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateWd()\n",
    "            self.updateXb()\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                rmse_train = self.evaluate_RMSE(self.Y)\n",
    "                #print('iter = %d, loss = %.4f, RMSE train = %.4f'%(it + 1,self.loss(), rmse_train))\n",
    "\n",
    "    def pred(self, u, i):\n",
    "        \"\"\"\n",
    "        predict the rating of user u for item i\n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]\n",
    "        return max(0, min(5, pred)) # 5-scale in MoviesLen\n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0] # number of test\n",
    "        SE = 0 # squared error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2])**2\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE\n",
    "\n",
    "    def evaluate_RMAE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0] # number of test\n",
    "        AE = 0 # absolute error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            AE += abs(pred - rate_test[n, 2])\n",
    "        MAE = AE / n_tests\n",
    "        return MAE\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "rs = MF(rate_train, K = 50, lam = .01, print_every = 5, learning_rate = 50,\n",
    "max_iter = 30)\n",
    "rs.fit()\n",
    "# evaluate on test data\n",
    "testRMSEMF = rs.evaluate_RMSE(rate_test)\n",
    "testRMAEMF=rs.evaluate_RMAE(rate_test)\n",
    "trainRMSEMF = rs.evaluate_RMSE(rate_train)\n",
    "trainRMAEMF=rs.evaluate_RMAE(rate_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values\n",
    "\n",
    "# Adjust user and movie IDs to start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "num_users = int(np.max(rate_train[:, 0])) + 1\n",
    "num_items = int(np.max(rate_train[:, 1])) + 1\n",
    "\n",
    "ratings_m = dok_matrix((num_users, num_items), dtype=np.float32)\n",
    "for i in range(rate_train.shape[0]):\n",
    "    user = rate_train[i, 0]\n",
    "    item = rate_train[i, 1]\n",
    "    rating = rate_train[i, 2]\n",
    "    ratings_m[user, item] = rating\n",
    "\n",
    "# Perform KMeans clustering\n",
    "k = int(num_users / 10) + 2  # You can adjust this value based on your needs\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clustering = kmeans.fit(ratings_m.tocsr())\n",
    "\n",
    "# Assign cluster labels to users\n",
    "user_clusters = clustering.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([79, 23, 13, 66, 80,  6, 29, 26, 66,  6,  8, 17, 84, 19, 57, 19, 23,\n",
       "       31, 66, 17,  5, 35, 19, 19, 17, 57, 66,  5, 66, 66, 66, 57, 66, 66,\n",
       "       66, 66, 26, 80, 66, 13, 17, 15, 75, 80, 57, 66, 66, 17, 19, 66, 66,\n",
       "       57, 66, 57, 66, 80, 57, 19, 50, 36, 66, 62, 57,  4,  8, 57, 66, 23,\n",
       "       57, 80, 17, 19, 17, 13, 57, 17, 17, 66, 23, 66, 57, 19, 80, 57, 31,\n",
       "       66, 35, 66, 57, 16, 19, 30, 66, 74,  4, 17, 17, 66, 32, 13, 57, 35,\n",
       "       66, 57, 66, 17, 66, 23,  3, 26, 13, 13, 23, 17, 19, 10, 57,  5, 32,\n",
       "       23, 17, 17, 17, 66,  8, 13, 66, 69, 66, 46, 23, 66, 66, 66,  5, 23,\n",
       "       57, 17, 66, 66, 57, 66, 66, 19,  9, 13, 66, 17, 13, 23, 39,  8, 66,\n",
       "       17, 66, 66, 23, 35,  1, 19, 17, 66, 66, 57, 66, 66, 66, 57, 66, 66,\n",
       "       13, 66, 13, 75, 17, 57, 19, 15, 13, 17,  0, 66, 66, 14, 23, 57,  8,\n",
       "       19, 67, 57, 13, 23, 57, 31, 23, 66, 26, 19, 23, 71, 41, 66, 57, 66,\n",
       "       66, 13,  8, 66, 23,  8, 66, 66, 19, 19, 19, 94, 26, 17, 66, 66, 26,\n",
       "       20, 57, 17, 66, 17, 23, 66, 13, 80, 66, 19, 19, 88, 17, 19, 17, 66,\n",
       "       85, 66, 66, 66, 23, 94, 66, 80, 66, 17, 79, 19, 57, 23, 19, 80,  5,\n",
       "       59, 23, 13, 17, 66, 66,  8,  6,  8, 57, 23, 35, 71, 38,  5, 31, 17,\n",
       "       13, 57, 80, 83, 57, 66, 48, 64, 66, 66,  8, 13, 66, 28, 57, 17, 66,\n",
       "       80, 94, 19,  2, 32, 71, 32, 19,  6,  6, 66,  3, 66, 76, 66, 19, 23,\n",
       "       80, 33, 66, 66, 60, 73, 31, 75, 19, 17, 66,  8, 66, 26,  6, 17, 17,\n",
       "       57, 19,  4, 15, 43, 23, 95, 23, 32, 66, 22, 66,  8, 23, 17, 31, 17,\n",
       "       66, 19, 81, 32, 75, 26, 94, 57,  1, 17, 13, 17, 66,  6, 66, 66, 57,\n",
       "       66, 66, 19, 19, 66, 71, 66, 23,  5,  5,  5, 66, 17, 17,  5, 71, 69,\n",
       "       66, 66, 66, 51,  4, 19, 19, 17, 17, 13,  6, 66, 44, 57, 91, 23, 19,\n",
       "       17, 40, 80, 17, 57, 19,  6, 94, 66,  8, 23, 57, 13, 24, 49, 71, 13,\n",
       "        6, 13, 17, 17, 23, 66, 66, 58, 54, 66, 17, 23, 17,  5, 13, 23, 26,\n",
       "        6, 13, 13, 86, 23, 66, 57, 23, 57, 37,  8, 69, 57, 23, 13, 66, 26,\n",
       "       66, 66, 57, 13, 32, 13, 23, 88, 10,  6, 94, 14, 80, 68, 62, 78, 32,\n",
       "       23, 66, 66, 32, 23, 17, 26, 23, 19, 17, 23, 66, 70, 23, 27, 66,  8,\n",
       "       66,  8, 15, 17, 17, 66, 23, 80, 66, 32, 56, 19, 10, 23, 23, 17, 19,\n",
       "       17,  4, 17, 37, 19, 19, 32, 57, 66,  6, 53, 80, 42, 13, 19, 66, 66,\n",
       "       66, 66, 66, 71, 13, 66, 66, 57, 13, 66, 80, 66,  8, 31, 57, 57, 19,\n",
       "       17, 13, 17, 13, 89, 15, 57, 93,  4, 27, 19, 23, 57, 80, 19, 35, 13,\n",
       "        3,  5, 13, 32, 66, 57, 18, 57,  6, 80, 57, 17, 66, 23, 17, 57, 31,\n",
       "       17, 66, 66, 66, 19,  6, 17, 57, 66, 66, 66, 17, 13, 66, 23, 80, 66,\n",
       "        8, 57, 23, 57, 66, 66,  7, 26, 10, 25, 13, 23,  8, 12, 75, 23, 57,\n",
       "       66, 23, 66, 57, 26, 19, 66, 66, 66, 19, 63, 66, 19, 66, 17, 13, 66,\n",
       "       66, 23,  8, 13,  5, 69, 26, 80, 80, 80, 17, 32, 19, 13, 26, 66, 19,\n",
       "       57, 66, 80, 17, 32, 66, 66, 57, 35,  7, 19, 66, 65, 35, 66, 19, 13,\n",
       "       17, 71, 66,  4, 66, 66, 35, 80, 72, 66, 66, 17,  6, 71, 15, 66, 32,\n",
       "       19, 19,  6, 17, 13, 19, 17, 26, 66, 13, 57, 66, 17, 57, 23, 17, 23,\n",
       "       66, 20, 13,  8, 66, 19, 66, 66, 57,  8, 66, 66, 19,  6, 13, 66, 32,\n",
       "       17, 32, 66, 13, 66, 57, 17, 80, 66, 47, 57, 26, 19, 69, 80, 13, 57,\n",
       "       79, 31, 32, 57, 17, 13, 10, 57, 66, 13, 66, 66, 11, 66, 66, 23, 17,\n",
       "       66, 23, 17, 23, 66, 66, 35, 66, 66,  8, 23, 23, 66, 17, 26, 31, 19,\n",
       "       71, 66,  8, 13, 17, 23, 13, 80, 26, 21, 57, 66, 57, 66, 19, 80, 66,\n",
       "        4, 66, 57, 66, 57, 17, 13, 19, 35, 13, 17, 66, 17, 57, 17, 17, 10,\n",
       "       13, 13, 66, 80, 13, 43, 23, 80, 66, 57, 57, 23, 80, 45, 66, 77, 66,\n",
       "       66, 13,  5, 66, 71, 55, 35,  4, 66, 66, 66, 66, 66, 66,  5,  4, 66,\n",
       "       66, 66, 13, 13, 17, 66, 79, 66, 32, 26, 66, 13, 23, 80, 17, 66, 35,\n",
       "       57, 19, 17, 23, 19, 23,  6, 13, 13,  4, 80, 66, 34, 80,  4, 66, 17,\n",
       "       92, 57, 13, 19, 66, 13, 66, 66, 66, 13, 23,  4, 10, 87, 23, 66, 19,\n",
       "       35, 23, 90, 13, 57, 66, 23, 19, 66, 17,  8, 66, 82,  4, 80, 35, 23,\n",
       "       80, 41, 80, 66, 52,  4, 57, 31, 57, 32, 66,  4,  4, 13, 15, 66, 80,\n",
       "       17, 19, 66, 23, 23,  0, 17, 66, 57,  8, 17, 19, 66, 13, 79, 23, 17,\n",
       "       32, 13, 80, 80, 57, 17, 66, 66, 80, 66, 17, 23, 13, 61, 35,  8, 57,\n",
       "       32, 23, 57, 57, 19, 66, 17, 26])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0453\n",
      "Test MAE: 0.8379\n"
     ]
    }
   ],
   "source": [
    "def get_cluster_recommendations(user_id, user_clusters, rate_train, top_n=8):\n",
    "    user_cluster = user_clusters[user_id]\n",
    "    cluster_user_ids = np.where(user_clusters == user_cluster)[0]\n",
    "    \n",
    "    # Aggregate ratings from the same cluster\n",
    "    product_scores = {}\n",
    "    for cluster_user_id in cluster_user_ids:\n",
    "        user_reviews = rate_train[rate_train[:, 0] == cluster_user_id]\n",
    "        for review in user_reviews:\n",
    "            product_id = review[1]\n",
    "            rating = review[2]\n",
    "            if product_id not in product_scores:\n",
    "                product_scores[product_id] = []\n",
    "            product_scores[product_id].append(rating)\n",
    "    \n",
    "    # Compute average score for each product\n",
    "    product_avg_scores = {product_id: np.mean(scores) for product_id, scores in product_scores.items()}\n",
    "    recommended_products = sorted(product_avg_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    return recommended_products\n",
    "\n",
    "def evaluate_performance(user_clusters, rate_test, rate_train):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(rate_test.shape[0]):\n",
    "        user_id = rate_test[i, 0]\n",
    "        item_id = rate_test[i, 1]\n",
    "        true_rating = rate_test[i, 2]\n",
    "        \n",
    "        # Get cluster recommendations\n",
    "        recommendations = get_cluster_recommendations(user_id, user_clusters, rate_train)\n",
    "        recommended_items = [item[0] for item in recommendations]\n",
    "        \n",
    "        if item_id in recommended_items:\n",
    "            predicted_rating = dict(recommendations).get(item_id, np.mean([r[1] for r in recommendations]))\n",
    "        else:\n",
    "            item_ratings = rate_train[rate_train[:, 1] == item_id][:, 2]\n",
    "            predicted_rating = np.mean(item_ratings) if len(item_ratings) > 0 else np.nan\n",
    "        \n",
    "        y_true.append(true_rating)\n",
    "        y_pred.append(predicted_rating)\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mask = ~np.isnan(y_pred)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    return rmse, mae\n",
    "\n",
    "# Evaluate performance\n",
    "rmse, mae = evaluate_performance(user_clusters, rate_test, rate_train)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values\n",
    "\n",
    "# Adjust user and movie IDs to start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "# Filter the dataset to include only 200 users\n",
    "unique_users = np.unique(rate_train[:, 0])\n",
    "selected_users = np.random.choice(unique_users, 200, replace=False)\n",
    "\n",
    "filtered_train = rate_train[np.isin(rate_train[:, 0], selected_users)]\n",
    "filtered_test = rate_test[np.isin(rate_test[:, 0], selected_users)]\n",
    "\n",
    "# Update user IDs to be continuous from 0 to 199\n",
    "user_mapping = {old_id: new_id for new_id, old_id in enumerate(np.unique(filtered_train[:, 0]))}\n",
    "filtered_train[:, 0] = np.vectorize(user_mapping.get)(filtered_train[:, 0])\n",
    "filtered_test[:, 0] = np.vectorize(user_mapping.get)(filtered_test[:, 0])\n",
    "\n",
    "num_users = 200\n",
    "num_items = int(np.max(rate_train[:, 1])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Create a sparse matrix from user reviews\n",
    "ratings_m = dok_matrix((num_users, num_items), dtype=np.float32)\n",
    "for i in range(filtered_train.shape[0]):\n",
    "    user = filtered_train[i, 0]\n",
    "    item = filtered_train[i, 1]\n",
    "    rating = filtered_train[i, 2]\n",
    "    ratings_m[user, item] = rating\n",
    "\n",
    "# Perform KMeans clustering\n",
    "k = int(num_users / 10) + 2  # You can adjust this value based on your needs\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clustering = kmeans.fit(ratings_m.tocsr())\n",
    "\n",
    "# Assign cluster labels to users\n",
    "user_clusters = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_recommendations(user_id, user_clusters, rate_train, top_n=8):\n",
    "    user_cluster = user_clusters[user_id]\n",
    "    cluster_user_ids = np.where(user_clusters == user_cluster)[0]\n",
    "    \n",
    "    # Aggregate ratings from the same cluster\n",
    "    product_scores = {}\n",
    "    for cluster_user_id in cluster_user_ids:\n",
    "        user_reviews = rate_train[rate_train[:, 0] == cluster_user_id]\n",
    "        for review in user_reviews:\n",
    "            product_id = review[1]\n",
    "            rating = review[2]\n",
    "            if product_id not in product_scores:\n",
    "                product_scores[product_id] = []\n",
    "            product_scores[product_id].append(rating)\n",
    "    \n",
    "    # Compute average score for each product\n",
    "    product_avg_scores = {product_id: np.mean(scores) for product_id, scores in product_scores.items() if len(scores) > 0}\n",
    "    recommended_products = sorted(product_avg_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    return recommended_products\n",
    "\n",
    "def evaluate_performance(user_clusters, rate_test, rate_train):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(rate_test.shape[0]):\n",
    "        user_id = rate_test[i, 0]\n",
    "        item_id = rate_test[i, 1]\n",
    "        true_rating = rate_test[i, 2]\n",
    "        \n",
    "        # Get cluster recommendations\n",
    "        recommendations = get_cluster_recommendations(user_id, user_clusters, rate_train)\n",
    "        recommended_items = [item[0] for item in recommendations]\n",
    "        \n",
    "        if item_id in recommended_items:\n",
    "            predicted_rating = dict(recommendations).get(item_id, np.mean([r[1] for r in recommendations]))\n",
    "        else:\n",
    "            item_ratings = rate_train[rate_train[:, 1] == item_id][:, 2]\n",
    "            predicted_rating = np.mean(item_ratings) if len(item_ratings) > 0 else np.nan\n",
    "        \n",
    "        y_true.append(true_rating)\n",
    "        y_pred.append(predicted_rating)\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mask = ~np.isnan(y_pred)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    return rmse, mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.9744\n",
      "Train MAE: 0.7682\n"
     ]
    }
   ],
   "source": [
    "train_rmse, train_mae = evaluate_performance(user_clusters, filtered_train, filtered_train)\n",
    "print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Train MAE: {train_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1185\n",
      "Test MAE: 0.8934\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "rmse, mae = evaluate_performance(user_clusters, filtered_test, filtered_train)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import dok_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "# Load data\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ua.test', sep='\\t', names=r_cols)\n",
    "rate_train = ratings_base.values\n",
    "rate_test = ratings_test.values\n",
    "\n",
    "# Adjust user and movie IDs to start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1\n",
    "\n",
    "num_users = int(np.max(rate_train[:, 0])) + 1\n",
    "num_items = int(np.max(rate_train[:, 1])) + 1\n",
    "\n",
    "# Create a sparse matrix from user reviews\n",
    "ratings_m = dok_matrix((num_users, num_items), dtype=np.float32)\n",
    "for i in range(rate_train.shape[0]):\n",
    "    user = rate_train[i, 0]\n",
    "    item = rate_train[i, 1]\n",
    "    rating = rate_train[i, 2]\n",
    "    ratings_m[user, item] = rating\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=200)  # You can adjust the number of components\n",
    "ratings_m_pca = pca.fit_transform(ratings_m.tocsr().toarray())\n",
    "\n",
    "# Perform KMeans clustering\n",
    "k = int(num_users / 10) + 2  # You can adjust this value based on your needs\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clustering = kmeans.fit(ratings_m_pca)\n",
    "\n",
    "# Assign cluster labels to users\n",
    "user_clusters = clustering.labels_\n",
    "\n",
    "def get_cluster_recommendations(user_id, user_clusters, rate_train, top_n=8):\n",
    "    user_cluster = user_clusters[user_id]\n",
    "    cluster_user_ids = np.where(user_clusters == user_cluster)[0]\n",
    "    \n",
    "    # Aggregate ratings from the same cluster\n",
    "    product_scores = {}\n",
    "    for cluster_user_id in cluster_user_ids:\n",
    "        user_reviews = rate_train[rate_train[:, 0] == cluster_user_id]\n",
    "        for review in user_reviews:\n",
    "            product_id = review[1]\n",
    "            rating = review[2]\n",
    "            if product_id not in product_scores:\n",
    "                product_scores[product_id] = []\n",
    "            product_scores[product_id].append(rating)\n",
    "    \n",
    "    # Compute average score for each product\n",
    "    product_avg_scores = {product_id: np.mean(scores) for product_id, scores in product_scores.items() if len(scores) > 0}\n",
    "    recommended_products = sorted(product_avg_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    return recommended_products\n",
    "\n",
    "def evaluate_performance(user_clusters, rate_data, rate_train):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(rate_data.shape[0]):\n",
    "        user_id = rate_data[i, 0]\n",
    "        item_id = rate_data[i, 1]\n",
    "        true_rating = rate_data[i, 2]\n",
    "        \n",
    "        # Get cluster recommendations\n",
    "        recommendations = get_cluster_recommendations(user_id, user_clusters, rate_train)\n",
    "        recommended_items = [item[0] for item in recommendations]\n",
    "        \n",
    "        if item_id in recommended_items:\n",
    "            predicted_rating = dict(recommendations).get(item_id, np.mean([r[1] for r in recommendations]))\n",
    "        else:\n",
    "            item_ratings = rate_train[rate_train[:, 1] == item_id][:, 2]\n",
    "            predicted_rating = np.mean(item_ratings) if len(item_ratings) > 0 else np.nan\n",
    "        \n",
    "        y_true.append(true_rating)\n",
    "        y_pred.append(predicted_rating)\n",
    "    \n",
    "    # Remove NaNs from y_pred and corresponding entries in y_true\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    mask = ~np.isnan(y_pred)\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    return rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.1166\n",
      "Test MAE: 0.8912\n",
      "Train RMSE: 0.9697\n",
      "Train MAE: 0.7601\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on test data\n",
    "test_rmse, test_mae = evaluate_performance(user_clusters, filtered_test, filtered_train)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "# Evaluate performance on training data\n",
    "train_rmse, train_mae = evaluate_performance(user_clusters, filtered_train, filtered_train)\n",
    "print(f\"Train RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Train MAE: {train_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model  Train RMSE  Test RMSE  Train MAE  Test MAE\n",
      "0      MF    0.911142   0.962120   0.718700  0.756727\n",
      "1      CF    0.742342   0.976614   0.609017  0.769020\n",
      "2  Kmeans    0.969707   1.116597   0.760080  0.891203\n"
     ]
    }
   ],
   "source": [
    "comparison_table = pd.DataFrame({\n",
    "    'Model': ['MF', 'CF','Kmeans'],\n",
    "    'Train RMSE': [trainRMSEMF, trainRMSECF,train_rmse],\n",
    "    'Test RMSE': [testRMSEMF, testRMSECF,test_rmse],\n",
    "    'Train MAE': [trainRMAEMF, trainRMAECF,train_mae],\n",
    "    'Test MAE': [testRMAEMF, testRMAECF,test_mae]\n",
    "})\n",
    "\n",
    "print(comparison_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
